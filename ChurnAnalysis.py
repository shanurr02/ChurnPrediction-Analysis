# -*- coding: utf-8 -*-
"""ChurnAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pOHXDNzjFN2OoHxxqCQyL6xC5nJ1X-EC
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



import os
for dirname, _, filenames in os.walk('/inputData'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore')

"""# Basic Explore Dataset"""

df_churn = pd.read_csv('./inputData/telecom_customer_churn.csv')
print('Tp 5 Glimpse Dataset of Cust Churn:\n')
df_churn.head()

print(f'Dataset have {df_churn.shape[0]} rows and {df_churn.shape[1]} columns\n')
print('Information of Dataset:\n')
df_churn.info()

table = pd.DataFrame({
    "No Unique" : df_churn.nunique(),
    "Missing Value": df_churn.isnull().sum(),
    'NaNN Value': df_churn.isna().sum(),
    'Duplicated' : df_churn.duplicated().sum(),
    'Dtype': df_churn.dtypes
})

table

df_churn.describe()

"""**Conclusion** :
1. Dataset have 8946 rows and 38 columns  
2. There are missing value = NaNN Value. Treatment each data NaNN will be process
3. No Duplicated data

# Formatting and Cleaning Dataset
"""

df_copy = df_churn.copy()

# Delet Unused Columns
df_copy.drop(columns = ['Zip Code', 'Latitude', 'Longitude', 'City'],axis =1, inplace = True)

# Library for visualization of missing value
import missingno as msno
msno.matrix(df_copy)

# Using KNNeighbors for imputing missing value
from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(n_neighbors=2, weights="uniform")
df_copy['Avg Monthly GB Download'] = knn_imputer.fit_transform(df_copy[['Avg Monthly GB Download']])
df_copy['Avg Monthly Long Distance Charges'] = knn_imputer.fit_transform(df_copy[['Avg Monthly Long Distance Charges']])

# SimpleImputer for categorical using strategy = most_frequent

from sklearn.impute import SimpleImputer

#setting strategy 'most_freq' to impute by the mode
const_imputer = SimpleImputer(strategy='most_frequent')
df_copy['Churn Reason'] = const_imputer.fit_transform(df_copy[['Churn Reason']])
df_copy['Churn Category'] = const_imputer.fit_transform(df_copy[['Churn Category']])
df_copy['Unlimited Data'] = const_imputer.fit_transform(df_copy[['Unlimited Data']])
df_copy['Streaming Music'] = const_imputer.fit_transform(df_copy[['Streaming Music']])
df_copy['Streaming Movies'] = const_imputer.fit_transform(df_copy[['Streaming Movies']])
df_copy['Streaming TV'] = const_imputer.fit_transform(df_copy[['Streaming TV']])
df_copy['Premium Tech Support'] = const_imputer.fit_transform(df_copy[['Premium Tech Support']])
df_copy['Device Protection Plan'] = const_imputer.fit_transform(df_copy[['Device Protection Plan']])
df_copy['Online Backup'] = const_imputer.fit_transform(df_copy[['Online Backup']])
df_copy['Online Security'] = const_imputer.fit_transform(df_copy[['Online Security']])
df_copy['Internet Type'] = const_imputer.fit_transform(df_copy[['Internet Type']])
df_copy['Multiple Lines'] = const_imputer.fit_transform(df_copy[['Multiple Lines']])

df_copy.info()

"""# Simple Visualization"""

# create figure and axes
fig, ax = plt.subplots(figsize=(15, 7), dpi=100)
# ax.tick_params(axis='y', rotation=45)
# plot to the existing fig, by using ax=ax
p = sns.histplot(data=df_copy, y='Churn Reason', ax=ax)

"""<h2> Insight : </h2>
<p>the cause of the most customer churn is Competito had better devices </p>
"""

cat = df_copy.select_dtypes(include = "O")



# visualization to display statements from churn, stay and join from categorical data

plt.figure(figsize=(35,45))
for i, col in enumerate(cat.columns):
    axes = plt.subplot(11,3, i + 1)
    sns.countplot(x=cat[col], hue = df_copy['Customer Status'])
plt.tight_layout()
plt.xticks(rotation = 20, fontsize = 10)
plt.show()

num = df_copy.select_dtypes(exclude = 'O')

plt.figure(figsize=(35,45))
for i, col in enumerate(num.columns):
    axes = plt.subplot(11,3, i + 1)
    sns.histplot(x=num[col], hue = df_copy['Customer Status'])
plt.tight_layout()
plt.xticks(rotation = 20, fontsize = 10)
plt.show()

"""**CONCLUSION** :

From data visualization we can conclude that the causes of churn :

1. Type of offer E is the biggest contributor to customers leaving the company, in contrast to offers A and B which make customers stayed

2. People who do not use services such as Internet Service, Multiple Lines, Online Back up more chrun than stayed

3. The most visible thing is that the monthly contract factor is the main cause of people churning

# PreProcessing
"""

df_copy["Customer Status"].unique()

# delete the joined data row, the prediction only focuses on Churn or Stayed

df_copy = df_copy.loc[df_copy["Customer Status"] != 'Joined']

df_copy.shape

# Label Encode for Cust Status

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_copy['Customer Status'] = le.fit_transform(df_copy['Customer Status'])

num_col = list(df_copy.describe().columns)
cat_col = list(set(df_copy.columns).difference(num_col))

plt.figure(figsize=(24,8))

# Mask for the upper triangle
mask = np.zeros_like(df_copy[num_col].corr(), dtype=np.bool)
mask[np.triu_indices_from(mask)] = True

# Generate a custom diverging colormap
#cmap = sns.diverging_palette(10, 220, as_cmap=True)
cmap = sns.light_palette((210, 90, 60), input="husl")

# Heatmap with mask
sns.heatmap(df_copy[num_col].corr(), mask=mask, cmap=cmap, annot=True, fmt=".2f");