# -*- coding: utf-8 -*-
"""ChurnPrdecitonFinalCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Q_TPEMUcmy6pf3IDydBweK6mrtUcix9E
"""

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)



import os
for dirname, _, filenames in os.walk('/inputData'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

import warnings
warnings.filterwarnings('ignore')

df_churn = pd.read_csv('./inputData/telecom_customer_churn.csv')
print('Data set:\n')
df_churn.head()

print(f'Dataset have {df_churn.shape[0]} rows and {df_churn.shape[1]} columns\n')
print('Information of Dataset:\n')
df_churn.info()

table = pd.DataFrame({
    "No Unique" : df_churn.nunique(),
    "Missing Value": df_churn.isnull().sum(),
    'NaNN Value': df_churn.isna().sum(),
    'Duplicated' : df_churn.duplicated().sum(),
    'Dtype': df_churn.dtypes
})

table

df_churn.describe()

"""**Conclusion** :
1. Dataset have 8946 rows and 38 columns

# Formatting and Cleaning Dataset
"""

df_copy = df_churn.copy()

# Delet Unused Columns
df_copy.drop(columns = ['Zip Code', 'Latitude', 'Longitude', 'City'],axis =1, inplace = True)

# Using KNNeighbors for imputing missing value
from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(n_neighbors=2, weights="uniform")
df_copy['Avg Monthly GB Download'] = knn_imputer.fit_transform(df_copy[['Avg Monthly GB Download']])
df_copy['Avg Monthly Long Distance Charges'] = knn_imputer.fit_transform(df_copy[['Avg Monthly Long Distance Charges']])

# SimpleImputer for categorical using strategy = most_frequent

from sklearn.impute import SimpleImputer

#setting strategy 'most_freq' to impute by the mode
const_imputer = SimpleImputer(strategy='most_frequent')
df_copy['Churn Reason'] = const_imputer.fit_transform(df_copy[['Churn Reason']])
df_copy['Churn Category'] = const_imputer.fit_transform(df_copy[['Churn Category']])
df_copy['Unlimited Data'] = const_imputer.fit_transform(df_copy[['Unlimited Data']])
df_copy['Streaming Music'] = const_imputer.fit_transform(df_copy[['Streaming Music']])
df_copy['Streaming Movies'] = const_imputer.fit_transform(df_copy[['Streaming Movies']])
df_copy['Streaming TV'] = const_imputer.fit_transform(df_copy[['Streaming TV']])
df_copy['Premium Tech Support'] = const_imputer.fit_transform(df_copy[['Premium Tech Support']])
df_copy['Device Protection Plan'] = const_imputer.fit_transform(df_copy[['Device Protection Plan']])
df_copy['Online Backup'] = const_imputer.fit_transform(df_copy[['Online Backup']])
df_copy['Online Security'] = const_imputer.fit_transform(df_copy[['Online Security']])
df_copy['Internet Type'] = const_imputer.fit_transform(df_copy[['Internet Type']])
df_copy['Multiple Lines'] = const_imputer.fit_transform(df_copy[['Multiple Lines']])

df_copy.info()

"""# PreProcessing"""

df_copy["Customer Status"].unique()

# delete the joined data row, the prediction only focuses on Churn or Stayed

df_copy = df_copy.loc[df_copy["Customer Status"] != 'Joined']

df_copy.shape

# Label Encode for Cust Status

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
df_copy['Customer Status'] = le.fit_transform(df_copy['Customer Status'])

num_col = list(df_copy.describe().columns)
cat_col = list(set(df_copy.columns).difference(num_col))

num_col.remove('Customer Status')

num_col

df_cat = pd.get_dummies(df_copy[cat_col])
df_cat.head()

X = pd.concat([df_copy[num_col], df_cat], axis=1)
X.head()

y = df_copy['Customer Status']
y.value_counts()

from sklearn.preprocessing import StandardScaler
X = StandardScaler().fit_transform(X)

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X = scaler.fit_transform(X)

from imblearn.over_sampling import RandomOverSampler

oversample = RandomOverSampler(sampling_strategy='minority')

X, y = oversample.fit_resample(X, y)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25)

"""# Modelling"""

from sklearn import preprocessing
from sklearn.model_selection import cross_val_score, cross_val_predict
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, roc_auc_score
from sklearn.metrics import mean_squared_error

# Calculation Model Loss


def loss(model, X_test, y_test):
    predictions = model.predict(X_test)
    mse = mean_squared_error(y_test, predictions)
    return mse


def print_score(clf, X_train, X_test,X_val, y_train, y_test,y_val, train=1):

    lb = preprocessing.LabelBinarizer()
    lb.fit(y_train)
    if train ==1:
        '''
        training performance
        '''
        res = clf.predict(X_train)
        print("Train Result:\n")
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_train,res)))


        print("Classification Report: \n {}\n".format(classification_report(y_train,res)))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_train,res)))
        print("ROC AUC: {0:.4f}\n".format(roc_auc_score(lb.transform(y_train),lb.transform(res))))

        res = cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy')
        print("Average Accuracy: \t {0:.4f}".format(np.mean(res)))
        print("Accuracy SD: \t\t {0:.4f}".format(np.std(res)))
        print("-------------------------------------------------------------------------")

    elif train== 0:
        '''
        test performance
        '''
        res_test = clf.predict(X_test)
        print("Test Result:\n")
        print("accuracy score: {0:.4f}\n".format(accuracy_score(y_test,res_test)))
        print("Testing Loss : ", loss(clf, X_test, y_test))

        print("Classification Report: \n {}\n".format(classification_report(y_test,
                                                                            res_test)))
        print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_test,
                                                                  res_test)))
        print("ROC AUC: {0:.4f}\n".format(roc_auc_score(lb.transform(y_test),
                                                      lb.transform(res_test))))
        print("-------------------------------------------------------------------------")


    elif train == 2:
      '''
        Validation  performance
        '''
      res_val = clf.predict(X_val)
      print("Validation Result:\n")
      print("accuracy score: {0:.4f}\n".format(accuracy_score(y_val,res_val)))
      print("Validation Loss : ", loss(clf, X_val, y_val))

      print("Classification Report: \n {}\n".format(classification_report(y_val,
                                                                            res_val)))
      print("Confusion Matrix: \n {}\n".format(confusion_matrix(y_val,
                                                                  res_val)))
      print("ROC AUC: {0:.4f}\n".format(roc_auc_score(lb.transform(y_val),
                                                      lb.transform(res_val))))
      print("-------------------------------------------------------------------------")

"""# Decision Tree Classifier"""

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(random_state=42)
clf.fit(X_train, y_train)

print_score(clf, X_train, X_test,X_val, y_train, y_test,y_val, train=1)
print_score(clf, X_train, X_test,X_val, y_train, y_test,y_val, train=2)
print_score(clf, X_train, X_test,X_val, y_train, y_test,y_val, train=0)

"""# Random Forest Classifier"""

from sklearn.ensemble import RandomForestClassifier
rfc = RandomForestClassifier(random_state=42, n_estimators=100)
rfc.fit(X_train, y_train)
print_score(rfc, X_train, X_test,X_val, y_train, y_test,y_val, train=1)
print_score(rfc, X_train, X_test,X_val, y_train, y_test,y_val, train=2)
print_score(rfc, X_train, X_test,X_val, y_train, y_test,y_val, train=0)

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=3, p=2, metric='minkowski')
knn.fit(X_train, y_train)

print_score(knn, X_train, X_test,X_val, y_train, y_test,y_val, train=1)
print_score(knn, X_train, X_test,X_val, y_train, y_test,y_val, train=2)
print_score(knn, X_train, X_test,X_val, y_train, y_test,y_val, train=0)

"""#USING XGB CLASSIFIER"""

from xgboost import XGBClassifier
bst = XGBClassifier(n_estimators=1000, learning_rate=0.001)
bst.fit(X_train, y_train)

print_score(bst, X_train, X_test,X_val, y_train, y_test,y_val, train=1)
print_score(bst, X_train, X_test,X_val, y_train, y_test,y_val, train=2)
print_score(bst, X_train, X_test,X_val, y_train, y_test,y_val, train=0)